{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dac16c8",
   "metadata": {},
   "source": [
    "# üêß This is the 2nd `LangGraph` Agentic AI application. \n",
    "\n",
    "### üö∂‚Äç‚û°Ô∏èHere are the following steps.\n",
    "0. Define the tools\n",
    "1. Set up the memory in SQLite DB\n",
    "1. Define the state class\n",
    "2. Start the Graph bulider\n",
    "3. Define the node\n",
    "4. Define the edges\n",
    "5. Compile the graph\n",
    "\n",
    "- `STATE` :  represents current snapshot of the application\n",
    "    - State is immutable\n",
    "- `NODE`  :  Python code that do the work. Take state as input and produce new state\n",
    "- `EDGE`  :  Edge choose what to do next\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td width=\"20%\">\n",
    "      <img src=\"../images/Agents_with_tools.png\" alt=\"Description Image\" style=\"width:100%;\">\n",
    "    </td>\n",
    "    <td width=\"80%\" style=\"vertical-align: top;\">\n",
    "      <ul>\n",
    "          <li> This application has use of tool. </li>\n",
    "          <li> This application has memory in SQLite\n",
    "      </ul>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10723941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel\n",
    "import random\n",
    "import os\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1094e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e12ed2",
   "metadata": {},
   "source": [
    "Here is the command that is used to run ollama 3.2\n",
    " - Open PowerShell\n",
    " - Run the command - `ollama run llama3.2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da357fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can choose any model to perform this operation. I am choosing a open model here ollama. Both the code are present over here.\n",
    "\n",
    "#Initialize Ollama instead of ChatOpenAI\n",
    "# llm = ChatOllama(\n",
    "#     model=\"llama3.2\",\n",
    "#     temperature=0,\n",
    "#     # base_url=\"http://localhost:11434\"  # Default value, usually not needed\n",
    "# )\n",
    "\n",
    "# Open AI Code. I commenting this code for now to use Ollama\n",
    "MODEL_NAME = os.getenv(key=\"MODEL_NAME\")\n",
    "llm = ChatOpenAI(model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac2fda",
   "metadata": {},
   "source": [
    "#### üî® Setting up the tool section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eb4dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search(SerpAPI) API set up details is present in the README file\n",
    "from langchain_community.utilities import SerpAPIWrapper\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "\n",
    "serper_client = SerpAPIWrapper()\n",
    "# serach.run(\"What is the capital of India?\")\n",
    "\n",
    "tool_google_search = Tool(\n",
    "    name=\"google_search\",\n",
    "    func=serper_client.run,\n",
    "    description=\"Useful for when you need to answer questions about current events, \"\n",
    "                \"people, or companies. Always use this tool if the user asks for \"\n",
    "                \"up-to-date information.\"\n",
    ")\n",
    "\n",
    "# Where is the sample code for calling the tool\n",
    "# tool_google_search.invoke(\"What is the capital of India?\")\n",
    "\n",
    "\n",
    "\n",
    "# Setting another tool for sending the output\n",
    "\n",
    "def send_information(text: str)-> str:\n",
    "    \"\"\"Send the notification via different channel as needed.\"\"\"\n",
    "    print(text)\n",
    "    return \"Information has been sent\"\n",
    "\n",
    "tool_send = Tool(\n",
    "    name=\"send_information\",\n",
    "    func=send_information,\n",
    "    description=\"Useful tool to send notification via different channel as needed.\"\n",
    ")    \n",
    "\n",
    "tools = [tool_google_search, tool_send]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209fbe7f",
   "metadata": {},
   "source": [
    "### ü™¶Setting up SQLite DB for memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60221e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "db_path = \"chat_memory.db\"\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)\n",
    "sql_memory = SqliteSaver(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72893689",
   "metadata": {},
   "source": [
    "üö∂‚Äç‚û°Ô∏èStep 1: Define the State class\n",
    "- State can a Pydentic BaseModel or TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):        \n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ddc7a2",
   "metadata": {},
   "source": [
    "üö∂‚Äç‚û°Ô∏èStep 2: Start the Graph Builder with the State Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e9f061",
   "metadata": {},
   "source": [
    "üö∂‚Äç‚û°Ô∏èStep 3: Define the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889634ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an llm object with tools\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chat_node(old_state: State) -> State:\n",
    "    response = llm_with_tools.invoke(old_state.messages)\n",
    "    new_state = State(messages=[response])\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chat_node)\n",
    "\n",
    "# create another node to call the tools\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e428f91d",
   "metadata": {},
   "source": [
    "üö∂‚Äç‚û°Ô∏èStep 4: Setup the edges\n",
    "- LangGraph will add a node with any unresolved node. That's I have not mentioned `chatbot` to `END` node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82623558",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition, \"tools\")\n",
    "graph_builder.add_edge( \"tools\",\"chatbot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad12280",
   "metadata": {},
   "source": [
    "üö∂‚Äç‚û°Ô∏èStep 5: Compile the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile(checkpointer=sql_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcff220",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"thread_id\":1}}\n",
    "def chat(user_input: str, history):\n",
    "    message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages = [message]\n",
    "    state = State(messages=messages)\n",
    "    result = graph.invoke(state, config=config)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
