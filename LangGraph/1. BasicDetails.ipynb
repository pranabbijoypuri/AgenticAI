{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dac16c8",
   "metadata": {},
   "source": [
    "# üêß This is the first `LangGraph` Agentic AI application. \n",
    "\n",
    "### üö∂‚Äç‚û°Ô∏èHere are the following steps.\n",
    "1. Define the state class\n",
    "2. Start the Graph bulider\n",
    "3. Define the node\n",
    "4. Define the edges\n",
    "5. Compile the graph\n",
    "\n",
    "- `STATE` :  represents current snapshot of the application\n",
    "    - State is immutable\n",
    "- `NODE`  :  Python code that do the work. Take state as input and produce new state\n",
    "- `EDGE`  :  Edge choose what to do next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10723941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_ollama import ChatOllama\n",
    "from pydantic import BaseModel\n",
    "import random\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1094e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52feb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = os.getenv(key=\"MODEL_NAME\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da357fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can choose any model to perform this operation. I am choosing a open model here ollama. Both the code are present \n",
    "# over here.\n",
    "\n",
    "# Initialize Ollama instead of ChatOpenAI\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\",\n",
    "    temperature=0,\n",
    "    # base_url=\"http://localhost:11434\"  # Default value, usually not needed\n",
    ")\n",
    "\n",
    "# Open AI Code. I commenting this code for now to use Ollama\n",
    "# llm = ChatOpenAI(model=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72893689",
   "metadata": {},
   "source": [
    "üö∂‚Äç‚û°Ô∏èStep 1: Define the State class\n",
    "- State can a Pydentic BaseModel or TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428714c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):        \n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ddc7a2",
   "metadata": {},
   "source": [
    "üö∂‚Äç‚û°Ô∏èStep 2: Start the Graph Builder with the State Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e9f061",
   "metadata": {},
   "source": [
    "üö∂‚Äç‚û°Ô∏èStep 3: Define the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889634ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_chat_node(old_state: State) -> State:\n",
    "\n",
    "    response = llm.invoke(old_state.messages)\n",
    "    new_state = State(messages=[response])\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"basic_chat\", basic_chat_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e428f91d",
   "metadata": {},
   "source": [
    "üö∂‚Äç‚û°Ô∏èStep 4: Setup the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82623558",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"basic_chat\")\n",
    "graph_builder.add_edge(\"basic_chat\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad12280",
   "metadata": {},
   "source": [
    "üö∂‚Äç‚û°Ô∏èStep 5: Compile the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ad4350",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcff220",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5abaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, history):\n",
    "    message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages = [message]\n",
    "    state = State(messages=messages)\n",
    "    result = graph.invoke(state)\n",
    "    print(result)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
